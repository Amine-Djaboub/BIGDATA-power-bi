{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUBbSX-OtWfX"
   },
   "source": [
    "# **Preparing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "executionInfo": {
     "elapsed": 14780,
     "status": "ok",
     "timestamp": 1741297982612,
     "user": {
      "displayName": "Amine Djaboub",
      "userId": "18422669504776025253"
     },
     "user_tz": -60
    },
    "id": "G8IphHyt8jRo",
    "outputId": "61f11611-8cb6-46da-c599-6ccbece4cdd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle authentication set up successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to kaggle.json (same directory as the notebook)\n",
    "json_path = os.path.join(os.getcwd(), \"kaggle.json\")\n",
    "\n",
    "# Move it to the correct Kaggle API location\n",
    "os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n",
    "os.system(f\"cp {json_path} ~/.kaggle/\")\n",
    "\n",
    "# Set correct permissions\n",
    "os.system(\"chmod 600 ~/.kaggle/kaggle.json\")\n",
    "\n",
    "print(\"Kaggle authentication set up successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1741297982662,
     "user": {
      "displayName": "Amine Djaboub",
      "userId": "18422669504776025253"
     },
     "user_tz": -60
    },
    "id": "3icuSrt6s7Qn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle authentication file moved to: g:\\BIGDATA\\TP3\\.kaggle\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the new .kaggle directory inside the working directory\n",
    "new_dir = os.path.join(os.getcwd(), \".kaggle\")\n",
    "\n",
    "# Create the kaggle directory if it doesn't exist\n",
    "os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "# Move kaggle.json to the correct location\n",
    "shutil.move(\"kaggle.json\", os.path.join(new_dir, \"kaggle.json\"))\n",
    "\n",
    "# Set the correct permissions\n",
    "os.chmod(os.path.join(new_dir, \"kaggle.json\"), 0o600)\n",
    "\n",
    "print(f\"Kaggle authentication file moved to: {new_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4914,
     "status": "ok",
     "timestamp": 1741297987580,
     "user": {
      "displayName": "Amine Djaboub",
      "userId": "18422669504776025253"
     },
     "user_tz": -60
    },
    "id": "k0koBMBLtAPR",
    "outputId": "cf1e41e6-6d3e-4c9e-8044-d54235e1776a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\makam-tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.7.4.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\makam-tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\makam-tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (2024.12.14)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\makam-tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (3.4.1)\n",
      "Requirement already satisfied: idna in c:\\users\\makam-tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\makam-tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (6.30.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\makam-tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\makam-tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\makam-tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\makam-tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (76.0.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\makam-tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in c:\\users\\makam-tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\makam-tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\makam-tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (2.3.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\makam-tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\makam-tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 212505,
     "status": "ok",
     "timestamp": 1741298200084,
     "user": {
      "displayName": "Amine Djaboub",
      "userId": "18422669504776025253"
     },
     "user_tz": -60
    },
    "id": "YXMJtaWztCHO",
    "outputId": "544889fc-3080-48e9-b39f-5826824575d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Makam-TECH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/mkechinov/ecommerce-behavior-data-from-multi-category-store?dataset_version_number=8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 1.13G/4.29G [14:57<41:57, 1.35MB/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkagglehub\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Download latest version\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m path = \u001b[43mkagglehub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset_download\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmkechinov/ecommerce-behavior-data-from-multi-category-store\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPath to dataset files:\u001b[39m\u001b[33m\"\u001b[39m, path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Makam-TECH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\kagglehub\\datasets.py:35\u001b[39m, in \u001b[36mdataset_download\u001b[39m\u001b[34m(handle, path, force_download)\u001b[39m\n\u001b[32m     33\u001b[39m h = parse_dataset_handle(handle)\n\u001b[32m     34\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownloading Dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh.to_url()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ...\u001b[39m\u001b[33m\"\u001b[39m, extra={**EXTRA_CONSOLE_BLOCK})\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m path, _ = \u001b[43mregistry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset_resolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Makam-TECH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\kagglehub\\registry.py:28\u001b[39m, in \u001b[36mMultiImplRegistry.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m impl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m._impls):\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m impl.is_supported(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     30\u001b[39m         fails.append(\u001b[38;5;28mtype\u001b[39m(impl).\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Makam-TECH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\kagglehub\\resolver.py:29\u001b[39m, in \u001b[36mResolver.__call__\u001b[39m\u001b[34m(self, handle, path, force_download)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mself\u001b[39m, handle: T, path: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m, *, force_download: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     17\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Optional[\u001b[38;5;28mint\u001b[39m]]:\n\u001b[32m     18\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Resolves a handle into a path with the requested file(s) and the resource's version number.\u001b[39;00m\n\u001b[32m     19\u001b[39m \n\u001b[32m     20\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m \u001b[33;03m        Some cases where version number might be missing: Competition datasource, API-based models.\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     path, version = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_resolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Note handles are immutable, so _resolve() could not have altered our reference\u001b[39;00m\n\u001b[32m     32\u001b[39m     register_datasource_access(handle, version)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Makam-TECH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\kagglehub\\http_resolver.py:130\u001b[39m, in \u001b[36mDatasetHttpResolver._resolve\u001b[39m\u001b[34m(self, h, path, force_download)\u001b[39m\n\u001b[32m    127\u001b[39m os.makedirs(os.path.dirname(archive_path), exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    129\u001b[39m \u001b[38;5;66;03m# First, we download the archive.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[43mapi_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marchive_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m _extract_archive(archive_path, out_path)\n\u001b[32m    134\u001b[39m \u001b[38;5;66;03m# Delete the archive\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Makam-TECH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\kagglehub\\clients.py:217\u001b[39m, in \u001b[36mKaggleApiV1Client.download_file\u001b[39m\u001b[34m(self, path, out_file, resource_handle, cached_path, extract_auto_compressed_file)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    216\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownloading from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     \u001b[43m_download_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_object\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hash_object:\n\u001b[32m    220\u001b[39m     actual_md5_hash = to_b64_digest(hash_object)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Makam-TECH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\kagglehub\\clients.py:276\u001b[39m, in \u001b[36m_download_file\u001b[39m\u001b[34m(response, out_file, size_read, total_size, hash_object)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total=total_size, initial=size_read, unit=\u001b[33m\"\u001b[39m\u001b[33mB\u001b[39m\u001b[33m\"\u001b[39m, unit_scale=\u001b[38;5;28;01mTrue\u001b[39;00m, unit_divisor=\u001b[32m1024\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m progress_bar:\n\u001b[32m    275\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(out_file, open_mode) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhash_object\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Makam-TECH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Makam-TECH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\response.py:1066\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1064\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1066\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1068\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m   1069\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Makam-TECH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\response.py:955\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    952\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) >= amt:\n\u001b[32m    953\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    957\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Makam-TECH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\response.py:879\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    876\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    878\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m879\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    882\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    887\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    888\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[32m    889\u001b[39m         \u001b[38;5;28mself\u001b[39m._fp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Makam-TECH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\response.py:862\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1()\n\u001b[32m    860\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    861\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m862\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Makam-TECH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Makam-TECH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Makam-TECH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1253\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1250\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1251\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1252\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Makam-TECH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1105\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1103\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1106\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1107\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"mkechinov/ecommerce-behavior-data-from-multi-category-store\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1741298200088,
     "user": {
      "displayName": "Amine Djaboub",
      "userId": "18422669504776025253"
     },
     "user_tz": -60
    },
    "id": "GF5Z8HZUtKNc",
    "outputId": "588a012f-62c2-4f49-db2f-78e0260d778a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/.cache/kagglehub/datasets/mkechinov/ecommerce-behavior-data-from-multi-category-store/versions/8/2019-Oct.csv\n",
      "/root/.cache/kagglehub/datasets/mkechinov/ecommerce-behavior-data-from-multi-category-store/versions/8/2019-Nov.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"/root/.cache/kagglehub/datasets/mkechinov/ecommerce-behavior-data-from-multi-category-store/versions/8\"\n",
    "\n",
    "# List all files\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRHPq4KatdB0"
   },
   "source": [
    "# **Preparing Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7523,
     "status": "ok",
     "timestamp": 1741298207604,
     "user": {
      "displayName": "Amine Djaboub",
      "userId": "18422669504776025253"
     },
     "user_tz": -60
    },
    "id": "jD0N0mzq3T0l",
    "outputId": "9e85c828-8f05-45b4-fe50-57577eed689b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask in /usr/local/lib/python3.11/dist-packages (2024.12.1)\n",
      "Collecting memory_profiler\n",
      "  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (18.1.0)\n",
      "Collecting fastparquet\n",
      "  Downloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask) (3.1.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from dask) (24.2)\n",
      "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask) (6.0.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask) (0.12.1)\n",
      "Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask) (8.6.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from memory_profiler) (5.9.5)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.11/dist-packages (from fastparquet) (2.9.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask) (3.21.0)\n",
      "Requirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd>=1.4.0->dask) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
      "Downloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: memory_profiler, fastparquet\n",
      "Successfully installed fastparquet-2024.11.0 memory_profiler-0.61.0\n"
     ]
    }
   ],
   "source": [
    "!pip install dask memory_profiler pandas pyarrow fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8943,
     "status": "ok",
     "timestamp": 1741298216551,
     "user": {
      "displayName": "Amine Djaboub",
      "userId": "18422669504776025253"
     },
     "user_tz": -60
    },
    "id": "Qd-wD-A83VmK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import time\n",
    "from memory_profiler import memory_usage\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ANc2KGh3ax4"
   },
   "source": [
    "# **Cleaning The Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "# Find all CSV files in the dataset folder\n",
    "csv_files = glob.glob(os.path.join(dataset_path, \"*.csv\"))\n",
    "\n",
    "# Function to convert 'YYYY-MMM.csv' to a comparable datetime format\n",
    "def extract_date(filename):\n",
    "    base_name = os.path.basename(filename).replace(\".csv\", \"\")  # Remove path and .csv\n",
    "    year, month_abbr = base_name.split(\"-\")  # Split by \"-\"\n",
    "    month_number = datetime.datetime.strptime(month_abbr, \"%b\").month  # Convert 'Oct' → 10\n",
    "    return datetime.datetime(int(year), month_number, 1)  # Return a datetime object\n",
    "\n",
    "# Get the latest file by sorting filenames (assuming format 'YYYY-MM.csv')\n",
    "latest_file = max(csv_files, key=os.path.getctime)\n",
    "\n",
    "print(f\"Processing latest file: {latest_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 500_000  \n",
    "sample_fraction = 0.1  # 10% of data\n",
    "\n",
    "chunks = []\n",
    "for chunk in pd.read_csv(latest_file, chunksize=chunk_size):\n",
    "    sampled_chunk = chunk.sample(frac=sample_fraction, random_state=42)  # Ensures reproducibility\n",
    "    chunks.append(sampled_chunk)\n",
    "\n",
    "sampled_data = pd.concat(chunks, ignore_index=True)\n",
    "sampled_data.to_csv(\"sampled_ecommerce_data.csv\", index=False)\n",
    "\n",
    "print(\"Sampled dataset saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1398020,
     "status": "ok",
     "timestamp": 1741299614578,
     "user": {
      "displayName": "Amine Djaboub",
      "userId": "18422669504776025253"
     },
     "user_tz": -60
    },
    "id": "WK27WlaZ6M00"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "file_path = os.path.join('sampled_ecommerce_data.csv')\n",
    "chunk_size = 500_000  # Adjust based on memory usage\n",
    "output_file = \"cleaned_ecommerce_data.csv\"\n",
    "\n",
    "first_chunk = True  # To handle writing headers correctly\n",
    "event_counter = 0  # Start event_id counter\n",
    "\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "    # Convert event_time to datetime\n",
    "    chunk[\"event_time\"] = pd.to_datetime(chunk[\"event_time\"], errors=\"coerce\")\n",
    "\n",
    "    # Remove duplicates\n",
    "    chunk.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Drop category_code and handle missing brand values\n",
    "    chunk.drop(columns=[\"category_code\"], inplace=True)\n",
    "    chunk.loc[:, \"brand\"] = chunk[\"brand\"].fillna(\"Unavailable\")\n",
    "\n",
    "    # Assign unique event_id\n",
    "    chunk[\"event_id\"] = range(event_counter, event_counter + len(chunk))\n",
    "    event_counter += len(chunk)  # Update the counter for the next chunk\n",
    "\n",
    "    # Save chunk to file\n",
    "    chunk.to_csv(output_file, mode=\"w\" if first_chunk else \"a\", header=first_chunk, index=False)\n",
    "\n",
    "    first_chunk = False  # Set to False after first write\n",
    "    del chunk  # Free memory\n",
    "    gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3vvXvfwL127"
   },
   "source": [
    "# **Exploring The Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 124463,
     "status": "ok",
     "timestamp": 1741299917921,
     "user": {
      "displayName": "Amine Djaboub",
      "userId": "18422669504776025253"
     },
     "user_tz": -60
    },
    "id": "xuRfZ_-VL5_0",
    "outputId": "d78fb6fc-b945-4b91-fce7-8117e0a45644"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6740146 entries, 0 to 6740145\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   event_time  object \n",
      " 1   event_type  object \n",
      " 2   product_id  int64  \n",
      " 3   brand       object \n",
      " 4   price       float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 257.1+ MB\n",
      "None\n",
      "         product_id         price\n",
      "count  6.740146e+06  6.740146e+06\n",
      "mean   1.251059e+07  2.924528e+02\n",
      "std    1.724944e+07  3.555930e+02\n",
      "min    1.000978e+06  0.000000e+00\n",
      "25%    1.305996e+06  6.924000e+01\n",
      "50%    5.100572e+06  1.657700e+02\n",
      "75%    1.730075e+07  3.603700e+02\n",
      "max    1.000286e+08  2.574070e+03\n",
      "event_type\n",
      "view        6355885\n",
      "cart         292489\n",
      "purchase      91772\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 500_000\n",
    "selected_cols = [\"event_time\", \"event_type\", \"product_id\", \"brand\", \"price\"]\n",
    "\n",
    "chunks = []\n",
    "for chunk in pd.read_csv(\"cleaned_ecommerce_data.csv\", usecols=selected_cols, chunksize=chunk_size):\n",
    "    chunks.append(chunk.sample(frac=0.1))  # Load only 10% of each chunk (adjust as needed)\n",
    "\n",
    "df = pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "\n",
    "print(df.info())  # Check data types & missing values\n",
    "print(df.describe())  # Summary stats for numerical columns\n",
    "print(df[\"event_type\"].value_counts())  # Count of each event type\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMUqrMTlXjUEil3k92e9a4w",
   "mount_file_id": "1CCRZYPHW3OGJZRtM3AoVI1pCoZi5kxEi",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
